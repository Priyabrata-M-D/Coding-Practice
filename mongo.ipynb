{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admin\n",
      "config\n",
      "db5556\n",
      "local\n"
     ]
    }
   ],
   "source": [
    "#step=1 connect to mongodb database\n",
    "client=MongoClient()\n",
    "# or client=MongoClient('localhost',27017)\n",
    "\n",
    "for d in client.list_database_names():\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['system.version']\n"
     ]
    }
   ],
   "source": [
    "#connecting to one particular database\n",
    "#db=client.db5556\n",
    "db=client['admin']\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "#retriving records from database\n",
    "cursor=db.system.version.find()\n",
    "for doc in cursor:\n",
    "    print(doc['version'])      \n",
    "    #print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from tscrape import scrape_twitter_data\n",
    "\n",
    "\n",
    "# Define a function to upload data to MongoDB\n",
    "def upload_to_mongodb(json_file):\n",
    "    # Connect to MongoDB\n",
    "    client = MongoClient('mongodb://localhost:27017')\n",
    "    db = client['twitter_scraping']\n",
    "    collection = db['scrapped1']\n",
    "    # Convert data to JSON records and Insert data into MongoDB\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    result = collection.insert_many(data)\n",
    "\n",
    "    # Retrieve the uploaded data from MongoDB\n",
    "    uploaded_data = list(collection.find())\n",
    "\n",
    "    return uploaded_data\n",
    "\n",
    "\n",
    "# Define the Streamlit app\n",
    "def main():\n",
    "    # Page title\n",
    "    st.title('Twitter Scraper')\n",
    "\n",
    "    # Get user input\n",
    "    hashtag = st.text_input('Hashtag/Keyword')\n",
    "    start_date = st.date_input('Start Date')\n",
    "    end_date = st.date_input('End Date')\n",
    "    max_tweets = st.number_input('Max Tweets')\n",
    "\n",
    "    # Scrape Twitter data\n",
    "    if st.button('Scrape'):\n",
    "        tweets_df = scrape_twitter_data(hashtag, start_date, end_date, max_tweets)\n",
    "\n",
    "        # Create JSON file\n",
    "        json_file = 'tweets.json'\n",
    "        tweets_df.to_json(json_file, orient='records')\n",
    "\n",
    "        # Display data in a table\n",
    "        st.write(tweets_df)\n",
    "\n",
    "        # Download data in CSV format\n",
    "        csv = tweets_df.to_csv(index=False)\n",
    "        b64 = base64.b64encode(csv.encode()).decode()\n",
    "        st.markdown('### Download CSV File')\n",
    "        href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"twitter_data.csv\">Download CSV</a>'\n",
    "        st.markdown(href, unsafe_allow_html=True)\n",
    "\n",
    "        # Download data in JSON format\n",
    "        json = tweets_df.to_json(orient='records')\n",
    "        b64 = base64.b64encode(json.encode()).decode()\n",
    "        st.markdown('### Download JSON File')\n",
    "        href = f'<a href=\"data:file/json;base64,{b64}\" download=\"twitter_data.json\">Download JSON</a>'\n",
    "        st.markdown(href, unsafe_allow_html=True)\n",
    "\n",
    "        # Upload data to MongoDB\n",
    "        if st.button('Upload to MongoDB'):\n",
    "            uploaded_data = upload_to_mongodb(json_file)\n",
    "            # Display result\n",
    "            st.write(f'{len(uploaded_data)} documents uploaded to MongoDB')\n",
    "            # Display the uploaded data in a table\n",
    "            st.write(pd.DataFrame(uploaded_data))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebad67f52a29b0206a12581b47023d96d9a8ba93c13e5c33ae278f26166e0551"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
